{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random Forest, Gradient Boosting and Histogram-Based Gradient Boosting mdoels using scikit learn library\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the candle stick time\n",
    "kline_time = \"5m\"\n",
    "label_name = \"Trend_1\"\n",
    "model_name = \"gb\"    #Must be rf, gb or hgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset\n",
    "ds = pd.read_csv(f\"../data/Data_{kline_time}_Ind.csv\",  delimiter=',', low_memory=True)\n",
    "ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop some columns to ensure better model scoring\n",
    "col_to_drop = ['OpenTime', 'Diff_1', 'qAssetVol', 'TbuybAssetVol', 'TbuyqAssetVol', 'Ignore']\n",
    "ds = ds.drop(labels=col_to_drop, axis=1)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataframe\n",
    "Y = ds[label_name].values\n",
    "\n",
    "X = ds.drop(labels= [label_name], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the model\n",
    "\n",
    "if model_name == \"rf\":\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=100, verbose=1, n_jobs=8)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "elif model_name == \"gb\":\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    model = GradientBoostingClassifier(n_estimators=100, verbose=1)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "elif model_name == \"hgb\":\n",
    "    from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "    model = GradientBoostingClassifier(n_estimators=100, verbose=1)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "else:\n",
    "    print(\"The model must be rf, gb or hgb!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the scores\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(Y_test, pred))\n",
    "print(\"Precision: \", metrics.precision_score(Y_test, pred))\n",
    "print(\"Recall: \", metrics.recall_score(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the results\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, pred, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=\"Random Forest\")\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the confusion matrix\n",
    "cm = metrics.confusion_matrix(Y_test, pred)\n",
    "metrics.ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the importance deatures\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "fimp = permutation_importance(model, X_test, Y_test, n_repeats=10)\n",
    "\n",
    "#Make a dataframe of importances\n",
    "\n",
    "data = {'Indicators' : X.columns.values, 'Importances': fimp.importances_mean}\n",
    "importances = pd.DataFrame(data)\n",
    "\n",
    "importances.sort_values(['Importances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make some predictions in pseudo random data from dataframe\n",
    "list_of_idx = []\n",
    "\n",
    "for _ in range(10):\n",
    "    list_of_idx.append(randint(0, len(ds)))\n",
    "\n",
    "for i in list_of_idx:\n",
    "\n",
    "    print(\"The index of data:\", i)\n",
    "    pred_one_value = ds.iloc[i]\n",
    "    print(\"Original value: \", pred_one_value[label_name])\n",
    "    pred_one_value = pred_one_value.drop(labels=[label_name])\n",
    "    prediction = np.array(pred_one_value.values)\n",
    "    prediction = prediction.reshape(1, -1)\n",
    "    one_pred = model.predict(prediction)\n",
    "    print(\"Prediction: \", one_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model using pickle\n",
    "import pickle\n",
    "\n",
    "with open(f\"saved-models/{model_name}_{kline_time}_{label_name}_acc{round(metrics.accuracy_score(Y_test, pred), 2)}.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
